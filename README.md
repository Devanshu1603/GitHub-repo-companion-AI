# ğŸ¤– GitHub Repository Companion â€“ AI Chatbot

An AI-powered chatbot that enables users to interact with the contents of any public GitHub repository in natural language. Simply provide a GitHub repo link, and the assistant can summarize code, explain logic, answer questions, and guide you through unfamiliar codebases â€” all powered by LLMs and a Retrieval-Augmented Generation (RAG) pipeline.

---

## ğŸš€ Features

- ğŸ”— Input any public GitHub repository URL
- ğŸ“ Automatically clones and parses relevant code files
- ğŸ§© Recursive chunking of code using header-aware logic
- ğŸ§  Embeds content using Gemini 1.5 Flash LLM
- ğŸ” Semantic search using ChromaDB (Vector DB)
- ğŸ’¬ Chat interface for asking contextual questions about the code
- â˜ï¸ Dockerized backend, deployable on AWS EC2

---

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** â€“ Python-based backend API
- **GitPython** â€“ GitHub repo cloning and file extraction
- **LangChain** â€“ RAG pipeline and LLM orchestration
- **Gemini 1.5 Flash** â€“ Googleâ€™s LLM for embeddings and response generation
- **ChromaDB** â€“ Lightweight vector store for semantic search
- **Docker** â€“ Containerized deployment
- **AWS EC2** â€“ Cloud deployment (optional)

### Frontend
- **React.js + TypeScript** â€“ Frontend app structure
- **Tailwind CSS** â€“ Responsive and utility-first styling
- **Vite** â€“ Lightning-fast dev server and bundler
- **Context API** â€“ State management
- **Component-based UI** â€“ Modular and reusable chat and input components

---

## ğŸ§  How It Works

```
User inputs GitHub URL
        â†“
Clone repo with GitPython
        â†“
Extract relevant source files (.py, .js, .md, etc.)
        â†“
Chunk files recursively (header-aware)
        â†“
Generate embeddings via Gemini LLM
        â†“
Store chunks & embeddings in ChromaDB
        â†“
User sends a query via chat
        â†“
Top relevant chunks retrieved from ChromaDB
        â†“
Gemini generates context-aware answer
        â†“
Response returned to frontend
```

---

## ğŸ“ Project Structure

```
ğŸ“¦github-repo-chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ repo_processor.py
â”‚   â”‚   â”œâ”€â”€ chunker.py
â”‚   â”‚   â”œâ”€â”€ embedder.py
â”‚   â”‚   â”œâ”€â”€ vector_db.py
â”‚   â”‚   â”œâ”€â”€ llm_wrapper.py
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ upload_repo.py
â”‚       â”œâ”€â”€ rag_query.py
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tailwind.config.ts
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md
```

---

## ğŸ”§ Backend Setup

```bash
cd backend
pip install -r requirements.txt
```

1. Create a `.env` file

```env
GEMINI_API_KEY=your_gemini_key
```

2. Run the FastAPI server

```bash
uvicorn main:app --reload
```

---

## ğŸ”§ Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

Visit: [http://localhost:5173](http://localhost:5173)

---

## ğŸ“¬ API Endpoints

| Method | Endpoint          | Description                          |
|--------|-------------------|--------------------------------------|
| POST   | `/upload-repo/`   | Clone and process GitHub repository |
| POST   | `/query/`         | Ask questions about the codebase    |

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ™‹â€â™‚ï¸ Author

**Devanshu Kumar Singh**  
ğŸ“§ singhdevanshu0803@gmail.com  
ğŸŒ [LinkedIn](https://linkedin.com/in/devanshu0803) | [GitHub](https://github.com/Devanshu1603)

---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to open issues, pull requests, or fork the project to improve its capabilities.
