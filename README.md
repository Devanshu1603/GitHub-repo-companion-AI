# ğŸ¤– GitHub Repository Companion â€“ AI Chatbot
```
This project implements an AI-powered GitHub assistant that combines retrieval-augmented generation (RAG), LangChain agents, and OpenAI's GPT-4o to provide natural language interaction with public GitHub repositories.
Upon receiving a GitHub URL, the system clones the repository, parses and chunks the source code, generates vector embeddings, and stores them in a semantic vector database (ChromaDB). Users can then ask questions like "explain this file," "find bugs," or "optimize performance," and the assistant uses a ReAct-based agent framework to route the query to the most appropriate tool (e.g., code explainer, bug finder, optimizer).
The system ensures minimal token usage through smart chunk-level retrieval and includes conversational memory to maintain multi-turn context. This allows developers to explore, understand, and refactor unfamiliar codebases quickly and intuitively â€” all through natural language queries.

```
---

## ğŸ“ Project Structure

```
ğŸ“¦ github-repo-companion-AI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry point
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ env.py              # Setting up .env contents
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ repo_processor.py   # Clones and filters repo files
â”‚   â”‚   â”œâ”€â”€ chunker.py          # Header-aware recursive chunking logic
â”‚   â”‚   â”œâ”€â”€ embedder.py         # Embedding generation using Gemini
â”‚   â”‚   â”œâ”€â”€ vector_db.py        # Search and storage logic for ChromaDB
â”‚   â”‚   â”œâ”€â”€ llm_wrapper.py      # Gemini LLM API integration
â”‚   â”‚   â””â”€â”€ retrieval.py        # Retrieves relevant code chunks for queries
â”‚   â”œâ”€â”€ tools/                  # LangChain tools + agents
â”‚   â”‚   â”œâ”€â”€ agent_executor.py   # Creates ReAct agent with tools + memory
â”‚   â”‚   â”œâ”€â”€ file_tree_builder.py# Create the cloned repo file directory
â”‚   â”‚   â”œâ”€â”€ multi_tool.py       # Contains functions for all tools to be used
â”‚   â”‚   â””â”€â”€ tool_registry.py    # Combines all tools into a unified list
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ upload_repo.py      # Upload repo + process endpoints
â”‚   â”‚   â”œâ”€â”€ chat.py             # Conversational endpoint using ReAct agent
â”‚   â”‚   â””â”€â”€ file_viewer.py      # Returns file structure + content
â”œâ”€â”€ project/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # React components for UI
â”‚   â”‚   â”œâ”€â”€ App.tsx             # Main app component
â”‚   â”‚   â””â”€â”€ ...                 # Other UI utilities
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tailwind.config.ts
â”‚   â”œâ”€â”€ vite.config.ts
â”œâ”€â”€ README.md                   # Project documentation
```


---

## ğŸ”§ Backend Setup

```bash
cd backend
pip install -r requirements.txt
```

1. Create a `.env` file

```env
GEMINI_API_KEY=your_gemini_key
OPENAI_API_KEY=your_openai_key
```

2. Run the FastAPI server

```bash
uvicorn main:app --reload
```

---

## ğŸ”§ Frontend Setup

```bash
cd project
npm install
npm run dev
```

Visit: [http://localhost:5173](http://localhost:5173)

---
## Dependencies

This project requires the following Python packages:

- fastapi
- uvicorn
- gitpython
- langchain
- chromadb
- google-generativeai
- python-dotenv
- tiktoken
- sentence-transformers

Make sure to install these packages using the `requirements.txt` file.

## ğŸ“¬ API Endpoints

| Method | Endpoint          | Description                          |
|--------|-------------------|--------------------------------------|
| POST   | `/upload-repo/`   | Clone and process GitHub repository |
| POST   | `/chat`           | Ask questions about the codebase |

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ™‹â€â™‚ï¸ Author

**Devanshu Kumar Singh**  
ğŸ“§ singhdevanshu0803@gmail.com  
ğŸŒ [LinkedIn](https://linkedin.com/in/devanshu0803) | [GitHub](https://github.com/Devanshu1603)

---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to open issues, pull requests, or fork the project to improve its capabilities.
